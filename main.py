#!/usr/bin/env python3
"""
Google Indexing API Bulk Tool
–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ URL-–æ–≤ –≤ Google Indexing API
"""

import json
import os
import sys
import time
import logging
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import argparse
from datetime import datetime
from urllib.parse import urlparse

try:
    import requests
    from google.oauth2 import service_account
    from google.auth.transport.requests import Request
except ImportError as e:
    print(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: pip install google-auth google-auth-oauthlib google-auth-httplib2 requests")
    sys.exit(1)


class GoogleIndexingBulk:
    """–ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Indexing API"""
    
    def __init__(self, service_account_path: str = "service_account.json"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å —Ñ–∞–π–ª–æ–º —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞
        
        Args:
            service_account_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É service_account.json
        """
        self.service_account_path = Path(service_account_path)
        self.credentials = None
        self.access_token = None
        self.service_account_email = None
        
        if not self.service_account_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª {service_account_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        
        self._authenticate()
        self._setup_logging()
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('indexing.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _authenticate(self):
        """–ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —á–µ—Ä–µ–∑ —Å–µ—Ä–≤–∏—Å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —É—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
            with open(self.service_account_path, 'r') as f:
                service_account_data = json.load(f)
            
            self.service_account_email = service_account_data.get('client_email')
            if not self.service_account_email:
                raise ValueError("Email —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ JSON —Ñ–∞–π–ª–µ")
            
            self.credentials = service_account.Credentials.from_service_account_file(
                self.service_account_path,
                scopes=['https://www.googleapis.com/auth/indexing']
            )
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω –¥–æ—Å—Ç—É–ø–∞
            self.credentials.refresh(Request())
            self.access_token = self.credentials.token
            
            print("‚úÖ –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
            print(f"üìß –°–µ—Ä–≤–∏—Å–Ω—ã–π –∞–∫–∫–∞—É–Ω—Ç: {self.service_account_email}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            raise
    
    def check_domain_ownership(self, urls: List[str]) -> Dict[str, List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–ª–∞–¥–µ–Ω–∏—è –¥–æ–º–µ–Ω–∞–º–∏
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL-–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–æ–º–µ–Ω–∞–º–∏ –∏ –∏—Ö —Å—Ç–∞—Ç—É—Å–æ–º
        """
        domains = {}
        for url in urls:
            domain = urlparse(url).netloc
            if domain not in domains:
                domains[domain] = []
            domains[domain].append(url)
        
        print(f"\nüîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–∞–¥–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞–º–∏...")
        print(f"üìß –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ {self.service_account_email} –¥–æ–±–∞–≤–ª–µ–Ω –∫–∞–∫ –≤–ª–∞–¥–µ–ª–µ—Ü –≤ Search Console –¥–ª—è:")
        
        for domain in domains:
            print(f"   - {domain}")
        
        return domains
    
    def submit_urls(self, urls: List[str], batch_size: int = 100, max_retries: int = 3) -> Dict:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ URL-–æ–≤ –≤ Google Indexing API
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL-–æ–≤ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            batch_size: –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 100)
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ—Ç–ø—Ä–∞–≤–∫–∏
        """
        if not urls:
            return {"success": False, "message": "–°–ø–∏—Å–æ–∫ URL-–æ–≤ –ø—É—Å—Ç"}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–ª–∞–¥–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞–º–∏
        self.check_domain_ownership(urls)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞
        batch_size = min(batch_size, 100)
        
        results = {
            "total_urls": len(urls),
            "batches": [],
            "success_count": 0,
            "error_count": 0,
            "errors": [],
            "domain_stats": {},
            "timestamp": datetime.now().isoformat()
        }
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø–∞–∫–µ—Ç—ã
        batches = [urls[i:i + batch_size] for i in range(0, len(urls), batch_size)]
        
        print(f"\nüì¶ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º {len(urls)} URL-–æ–≤ –≤ {len(batches)} –ø–∞–∫–µ—Ç–∞—Ö...")
        
        for i, batch in enumerate(batches, 1):
            print(f"   –ü–∞–∫–µ—Ç {i}/{len(batches)} ({len(batch)} URL-–æ–≤)...")
            
            batch_result = self._submit_batch_with_retry(batch, max_retries)
            results["batches"].append(batch_result)
            
            if batch_result["success"]:
                results["success_count"] += len(batch)
            else:
                results["error_count"] += len(batch)
                results["errors"].extend(batch_result.get("errors", []))
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏
            if i < len(batches):
                time.sleep(2)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–æ–º–µ–Ω–∞–º
        results["domain_stats"] = self._analyze_domain_stats(urls, results)
        
        return results
    
    def _submit_batch_with_retry(self, urls: List[str], max_retries: int) -> Dict:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –ø–∞–∫–µ—Ç–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL-–æ–≤ –¥–ª—è –ø–∞–∫–µ—Ç–∞
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç–∞
        """
        for attempt in range(max_retries):
            try:
                result = self._submit_batch(urls)
                
                if result["success"]:
                    return result
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—Ç–æ–∏—Ç –ª–∏ –ø–æ–≤—Ç–æ—Ä—è—Ç—å
                if "403" in result.get("error", "") and "ownership" in result.get("error", "").lower():
                    print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries})")
                    if attempt < max_retries - 1:
                        time.sleep(5 * (attempt + 1))  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
                        continue
                
                return result
                
            except Exception as e:
                error_msg = f"–û—à–∏–±–∫–∞ –≤ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}"
                print(f"   ‚ùå {error_msg}")
                
                if attempt < max_retries - 1:
                    time.sleep(5 * (attempt + 1))
                    continue
                
                return {
                    "success": False,
                    "urls_count": len(urls),
                    "error": error_msg
                }
        
        return {
            "success": False,
            "urls_count": len(urls),
            "error": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫"
        }
    
    def _submit_batch(self, urls: List[str]) -> Dict:
        """
        –û—Ç–ø—Ä–∞–≤–∫–∞ –æ–¥–Ω–æ–≥–æ –ø–∞–∫–µ—Ç–∞ URL-–æ–≤
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL-–æ–≤ –¥–ª—è –ø–∞–∫–µ—Ç–∞
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–∞–∫–µ—Ç–∞
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º multipart –¥–∞–Ω–Ω—ã–µ
        boundary = f"batch_{int(time.time())}"
        headers = {
            'Content-Type': f'multipart/mixed; boundary={boundary}',
            'Authorization': f'Bearer {self.access_token}'
        }
        
        body_parts = []
        
        for url in urls:
            # –§–æ—Ä–º–∏—Ä—É–µ–º —á–∞—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
            part_boundary = f"--{boundary}"
            content_id = f"<{int(time.time() * 1000)}>"
            
            # HTTP –∑–∞–≥–æ–ª–æ–≤–∫–∏
            http_headers = (
                f"POST /v3/urlNotifications:publish HTTP/1.1\r\n"
                f"Content-Type: application/json\r\n"
                f"Content-Length: {len(json.dumps({'url': url, 'type': 'URL_UPDATED'}))}\r\n\r\n"
            )
            
            # JSON –¥–∞–Ω–Ω—ã–µ
            json_data = json.dumps({
                'url': url,
                'type': 'URL_UPDATED'
            })
            
            # –°–æ–±–∏—Ä–∞–µ–º —á–∞—Å—Ç—å
            part = (
                f"{part_boundary}\r\n"
                f"Content-Type: application/http\r\n"
                f"Content-ID: {content_id}\r\n\r\n"
                f"{http_headers}"
                f"{json_data}\r\n"
            )
            
            body_parts.append(part)
        
        # –ó–∞–∫—Ä—ã–≤–∞—é—â–∞—è –≥—Ä–∞–Ω–∏—Ü–∞
        body_parts.append(f"--{boundary}--")
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
        body = "\r\n".join(body_parts)
        
        try:
            response = requests.post(
                'https://indexing.googleapis.com/batch',
                headers=headers,
                data=body.encode('utf-8'),
                timeout=30
            )
            
            if response.status_code == 200:
                return {
                    "success": True,
                    "urls_count": len(urls),
                    "response": response.text,
                    "status_code": response.status_code
                }
            else:
                return {
                    "success": False,
                    "urls_count": len(urls),
                    "error": f"HTTP {response.status_code}: {response.text}",
                    "status_code": response.status_code
                }
                
        except Exception as e:
            return {
                "success": False,
                "urls_count": len(urls),
                "error": str(e)
            }
    
    def _analyze_domain_stats(self, urls: List[str], results: Dict) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–æ–º–µ–Ω–∞–º
        
        Args:
            urls: –°–ø–∏—Å–æ–∫ URL-–æ–≤
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ø—Ä–∞–≤–∫–∏
        
        Returns:
            –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–º–µ–Ω–∞–º
        """
        domain_stats = {}
        
        for url in urls:
            domain = urlparse(url).netloc
            if domain not in domain_stats:
                domain_stats[domain] = {
                    "total_urls": 0,
                    "success_count": 0,
                    "error_count": 0
                }
            domain_stats[domain]["total_urls"] += 1
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ –¥–æ–º–µ–Ω–∞–º
        for batch in results["batches"]:
            if not batch["success"]:
                # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø–∞—Ä—Å–∏—Ç—å batch response
                pass
        
        return domain_stats


def load_urls_from_file(file_path: str) -> List[str]:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ URL-–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞
    
    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å URL-–∞–º–∏
    
    Returns:
        –°–ø–∏—Å–æ–∫ URL-–æ–≤
    """
    file_path = Path(file_path)
    
    if not file_path.exists():
        raise FileNotFoundError(f"–§–∞–π–ª {file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip()]
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è URL-–æ–≤
    valid_urls = []
    invalid_urls = []
    
    for url in urls:
        if url.startswith(('http://', 'https://')):
            valid_urls.append(url)
        else:
            invalid_urls.append(url)
    
    if invalid_urls:
        print(f"‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(invalid_urls)} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö URL-–æ–≤:")
        for url in invalid_urls[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
            print(f"   {url}")
        if len(invalid_urls) > 5:
            print(f"   ... –∏ –µ—â–µ {len(invalid_urls) - 5}")
    
    return valid_urls


def save_results(results: Dict, output_file: str = None):
    """
    –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª
    
    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ø—Ä–∞–≤–∫–∏
        output_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    """
    if not output_file:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"indexing_results_{timestamp}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")


def print_detailed_results(results: Dict):
    """
    –í—ã–≤–æ–¥ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    
    Args:
        results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç–ø—Ä–∞–≤–∫–∏
    """
    print("\n" + "="*60)
    print("üìä –î–ï–¢–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¢–ü–†–ê–í–ö–ò")
    print("="*60)
    print(f"–í—Å–µ–≥–æ URL-–æ–≤: {results['total_urls']}")
    print(f"–£—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {results['success_count']}")
    print(f"–û—à–∏–±–æ–∫: {results['error_count']}")
    print(f"–ü–∞–∫–µ—Ç–æ–≤: {len(results['batches'])}")
    print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {results.get('timestamp', 'N/A')}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–º–µ–Ω–∞–º
    if results.get('domain_stats'):
        print(f"\nüåê –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–º–µ–Ω–∞–º:")
        for domain, stats in results['domain_stats'].items():
            print(f"   {domain}: {stats['total_urls']} URL-–æ–≤")
    
    # –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫
    if results['errors']:
        print(f"\n‚ùå –û—Å–Ω–æ–≤–Ω—ã–µ –æ—à–∏–±–∫–∏:")
        error_types = {}
        for error in results['errors']:
            if "403" in error and "ownership" in error.lower():
                error_types["–ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞"] = error_types.get("–ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞", 0) + 1
            elif "429" in error:
                error_types["–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç"] = error_types.get("–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç", 0) + 1
            else:
                error_types["–î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏"] = error_types.get("–î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏", 0) + 1
        
        for error_type, count in error_types.items():
            print(f"   {error_type}: {count}")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    if results['error_count'] > 0:
        print("   1. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –∞–∫–∫–∞—É–Ω—Ç–∞ –≤ Search Console")
        print("   2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–æ–º–µ–Ω—ã –¥–æ–±–∞–≤–ª–µ–Ω—ã –≤ Search Console")
        print("   3. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å URL-–æ–≤")
    else:
        print("   ‚úÖ –í—Å–µ URL-—ã —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã!")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(
        description="Google Indexing API Bulk Tool - –ú–∞—Å—Å–æ–≤–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ URL-–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python main.py urls.txt
  python main.py urls.txt --batch-size 50
  python main.py urls.txt --service-account my_account.json
  python main.py urls.txt --save-results
  python main.py urls.txt --max-retries 5
        """
    )
    
    parser.add_argument(
        'urls_file',
        help='–§–∞–π–ª —Å URL-–∞–º–∏ (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)'
    )
    
    parser.add_argument(
        '--service-account',
        default='service_account.json',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É service_account.json (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: service_account.json)'
    )
    
    parser.add_argument(
        '--batch-size',
        type=int,
        default=100,
        help='–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ (–º–∞–∫—Å–∏–º—É–º 100, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 100)'
    )
    
    parser.add_argument(
        '--max-retries',
        type=int,
        default=3,
        help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 3)'
    )
    
    parser.add_argument(
        '--save-results',
        action='store_true',
        help='–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª'
    )
    
    parser.add_argument(
        '--output-file',
        help='–ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥'
    )
    
    args = parser.parse_args()
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º URL-—ã
        print(f"üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º URL-—ã –∏–∑ {args.urls_file}...")
        urls = load_urls_from_file(args.urls_file)
        
        if not urls:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö URL-–æ–≤!")
            return
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(urls)} –≤–∞–ª–∏–¥–Ω—ã—Ö URL-–æ–≤")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º API
        print("üîê –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Google Indexing API...")
        api = GoogleIndexingBulk(args.service_account)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º URL-—ã
        results = api.submit_urls(urls, args.batch_size, args.max_retries)
        
        # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print_detailed_results(results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if args.save_results or args.output_file:
            save_results(results, args.output_file)
        
        print("\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()